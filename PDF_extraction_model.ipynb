{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP7RzhO39hP7ioq6gekxpBB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ishikaaa/PDF-extraction/blob/main/PDF_extraction_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "6nRKB9HCa1PP"
      },
      "outputs": [],
      "source": [
        "!pip install PyPDF2\n",
        "!pip install langchain\n",
        "!pip install InstructorEmbedding\n",
        "!pip install sentence-transformers==2.2.2\n",
        "!pip install faiss-gpu\n",
        "!pip install -U langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline"
      ],
      "metadata": {
        "id": "x5pyVtQmbOrZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-1: get text from single OR multiple PDFs\n",
        "def get_pdf_text(pdf_docs):\n",
        "    \"\"\"\n",
        "    args:\n",
        "        pdf_docs: list of pdfs\n",
        "    \"\"\"\n",
        "    text = \"\"\n",
        "\n",
        "    # iterate through all pdfs\n",
        "    for pdf in pdf_docs:\n",
        "        pdf_reader = PdfReader(pdf)\n",
        "        # iterate through all pages\n",
        "        for page in pdf_reader.pages:\n",
        "            text += page.extract_text()\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "# Step-2: get the text chunks\n",
        "def get_text_chunks(text):\n",
        "    \"\"\"\n",
        "    : return\n",
        "        a list of chunks of text that we will feed to our model\n",
        "    \"\"\"\n",
        "    text_splitter = CharacterTextSplitter(\n",
        "        separator=\"\\n\",\n",
        "        chunk_size=1000,\n",
        "        chunk_overlap=200,\n",
        "        length_function=len,\n",
        "    )\n",
        "    chunks = text_splitter.split_text(text)\n",
        "    return chunks\n",
        "\n",
        "\n",
        "# Step-3: Create Vector store\n",
        "def get_vectorstore(text_chunks):\n",
        "    # instructor embeddings\n",
        "    embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-xl\")\n",
        "    vectorstore = FAISS.from_texts(texts=text_chunks, embedding=embeddings)\n",
        "    return vectorstore\n",
        "\n",
        "def train_model():\n",
        "    model_id = \"gpt2\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_id)\n",
        "\n",
        "    pipe = pipeline(\n",
        "    \"question-answering\", model=model, tokenizer=tokenizer, max_new_tokens=10\n",
        "    )\n",
        "\n",
        "    llm = HuggingFacePipeline(pipeline=pipe)\n",
        "\n",
        "    return llm\n"
      ],
      "metadata": {
        "id": "iMh9FechbMKv"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    pdf_docs = [\"NIPS-2017-attention-is-all-you-need-Paper.pdf\"]\n",
        "    raw_text = get_pdf_text(pdf_docs)\n",
        "\n",
        "    # Step-2: get the text chunks\n",
        "    text_chunks = get_text_chunks(raw_text)\n",
        "\n",
        "    # Step-3\n",
        "    vector_store = get_vectorstore(text_chunks)\n",
        "    print(\"text_chunks: \", vector_store)\n",
        "\n",
        "    # Step-4\n",
        "    llm_model = train_model()\n",
        "\n",
        "    # Step-5\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "pJplk5hobCQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-5\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "\n",
        "def step5():\n",
        "    query = \"what is Encoder and Decoder Stacks\"\n",
        "\n",
        "    docs = vector_store.similarity_search(query=query, k=3)\n",
        "    chain = load_qa_chain(llm=llm_model, chain_type=\"stuff\")\n",
        "    response = chain.run(input_documents=docs, question=query)\n",
        "\n",
        "    print(\"response: \", response)\n",
        "\n",
        "step5()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "kP3vGlcjTkuo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}